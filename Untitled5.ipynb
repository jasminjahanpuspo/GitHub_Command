{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": [],
      "mount_file_id": "1sLo1Fh9IkqQ7OBHzHLqicfi1Iu-D7G4D",
      "authorship_tag": "ABX9TyPpJW014sn1Clpu6U6K7zEn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/puspo1997/GitHub_Command/blob/master/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj6dl6vFyg_7"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from skimage.measure import label, regionprops\n",
        "\n",
        "\n",
        "class Preprocess:\n",
        "    def __init__(self, rawim, im, breast_mask, lesion_mask):\n",
        "        self.raw = rawim\n",
        "        self.image = im\n",
        "        self.mask = breast_mask\n",
        "        self.lesion_mask = lesion_mask\n",
        "   \n",
        "    def extract_breast_profile(image,lesion_mask, if_crop):\n",
        "        \n",
        "        breast_mask = np.zeros(np.shape(image))\n",
        "        breast_mask[image>0]=1\n",
        "        \n",
        "        labelim = label(breast_mask)\n",
        "        props =  regionprops(labelim)\n",
        "#        find the largest object as the breast\n",
        "        area = 0\n",
        "        ind = 1\n",
        "        for i in range(0,len(props)):\n",
        "            if area<props[i].filled_area:\n",
        "                area = props[i].filled_area\n",
        "                ind = i+1\n",
        "        breast_mask = np.zeros(np.shape(image))\n",
        "        breast_mask[labelim==ind]=1  \n",
        "        labelim = label(breast_mask)       \n",
        "        props =  regionprops(labelim)\n",
        "        boundingbox = props[0].bbox\n",
        "#        crop the breast mask and mammogram\n",
        "        if if_crop == 1:\n",
        "            breast_mask = breast_mask[boundingbox[0]:boundingbox[2],boundingbox[1]:boundingbox[3]]\n",
        "            breast_raw_image = image[boundingbox[0]:boundingbox[2],boundingbox[1]:boundingbox[3]]\n",
        "            lesion_mask = lesion_mask[boundingbox[0]:boundingbox[2],boundingbox[1]:boundingbox[3]]\n",
        "        else:\n",
        "            breast_raw_image = image\n",
        "#        breast_image = rescale2uint8(breast_raw_image,breast_mask)\n",
        "        breast_image = rescale2uint16(breast_raw_image,breast_mask)\n",
        "        return Preprocess(breast_raw_image,breast_image,breast_mask,lesion_mask)\n",
        "    \n",
        "def rescale2uint8(image,breast_mask):\n",
        "    intensity_in_mask = image[breast_mask>0]\n",
        "#    use top 0.2 percentile to do the strech\n",
        "    maxi = np.percentile(intensity_in_mask,99.8)#np.max(intensity_in_mask)\n",
        "    mini = np.percentile(intensity_in_mask,0.2)#np.min(intensity_in_mask)\n",
        "#        stretch the image into 0~255\n",
        "    \n",
        "    image = 255*(image-mini)/(maxi-mini)\n",
        "    image[breast_mask==0] = 0\n",
        "    image[image<0] = 0\n",
        "    image[image>255] = 255\n",
        "    image = np.uint8(image)\n",
        "          \n",
        "    return image\n",
        "\n",
        "def rescale2uint16(image,breast_mask):\n",
        "    intensity_in_mask = image[breast_mask>0]\n",
        "#    use top 0.2 percentile to do the strech\n",
        "    maxi = np.percentile(intensity_in_mask,99.8)#np.max(intensity_in_mask)\n",
        "    mini = np.percentile(intensity_in_mask,0.2)#np.min(intensity_in_mask)\n",
        "#        stretch the image into 0~255\n",
        "    \n",
        "    image = 65535*(image-mini)/(maxi-mini)\n",
        "    image[breast_mask==0] = 0\n",
        "    image[image<0] = 0\n",
        "    image[image>65535] = 65535\n",
        "    image = np.uint16(image)\n",
        "          \n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceq3ws4Syh0p"
      },
      "source": [
        "import numpy as np\n",
        "# To pad image into a square shape\n",
        "def padimages(image,file_name, ratio):\n",
        "    [length, width] = np.shape(image)\n",
        "    if length/width>ratio:#1024/800\n",
        "        print('This image needs padding.')\n",
        "        add_wid = round(length*(1/ratio)-width)\n",
        "        pad = np.zeros((length,add_wid))\n",
        "        pad = pad.astype(image.dtype)\n",
        "        if '_R_' in file_name:\n",
        "        #                pad on the left\n",
        "            pad_image = np.concatenate((pad,image),axis=1)\n",
        "        else:\n",
        "            pad_image = np.concatenate((image,pad),axis=1)\n",
        "            \n",
        "    return pad_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AkT0hjmyh3X"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import data, color, io, img_as_float\n",
        "\n",
        "def mask_overlay(img, mask):\n",
        "    alpha = 0.5\n",
        "\n",
        "    img = img_as_float(img)\n",
        "    rows, cols = img.shape\n",
        "    # Construct RGB version of grey-level image\n",
        "    img_color = np.dstack((img, img, img))\n",
        "    img_hsv = color.rgb2hsv(img_color)\n",
        "    color_mask = np.zeros((rows, cols, 3))\n",
        "    color_mask1 = color_mask[:,:,1]\n",
        "    color_mask1[np.where(mask>0)] = 1\n",
        "    color_mask[:,:,1] = color_mask1\n",
        "    color_mask_hsv = color.rgb2hsv(color_mask)\n",
        "    \n",
        "    # Replace the hue and saturation of the original image\n",
        "    # with that of the color mask\n",
        "    img_hsv[..., 0] = color_mask_hsv[..., 0]\n",
        "    img_hsv[..., 1] = color_mask_hsv[..., 1] * alpha\n",
        "    \n",
        "    img_masked = color.hsv2rgb(img_hsv)\n",
        "    \n",
        "    return img_masked"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gyj5Uz3ysJ7",
        "outputId": "d747b6c6-5172-46a5-acc5-55c664b97d20"
      },
      "source": [
        "cd '/content/drive/MyDrive/Mammographic/Mask_r_cnn'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Mammographic/Mask_r_cnn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guoFw9nKysNi",
        "outputId": "cf9a7504-6e87-43f8-cdbb-c6ca89d6135f"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Nov 26 15:46:32 2018\n",
        "\n",
        "@author: Hang Min\n",
        "\n",
        "Prepare the mammograms for pseudo-color transformation\n",
        "\n",
        "To normalize the INbreast mammogram to 16bit\n",
        "\n",
        "To pad the mammograms and masks to a square\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "#from Preprocess_mammo import Preprocess \n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "#from utility import padimages\n",
        "#from skimage.segmentation import mark_boundaries\n",
        "from skimage import io\n",
        "from skimage.measure import label\n",
        "#from overlay import mask_overlay\n",
        "import timeit\n",
        "\n",
        "start = timeit.default_timer()\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#from skimage import data, color, io, img_as_float\n",
        "\n",
        "image_path = \"scans/raw_mammogram/\"\n",
        "annotation_path = 'scans/raw_annotation/'\n",
        "\n",
        "save_image_path = \"scans/preprocessed_image/\"   \n",
        "if not os.path.exists(save_image_path):        \n",
        "    os.mkdir(save_image_path)\n",
        " \n",
        "    \n",
        "save_mask_path = \"scans/preprocessed_mask/\"    \n",
        "if not os.path.exists(save_mask_path):        \n",
        "    os.mkdir(save_mask_path)\n",
        "\n",
        "\n",
        "file_names = os.listdir(image_path)    \n",
        "file_names = sorted(file_names)\n",
        "\n",
        "\n",
        "for i in range(0,len(file_names)):\n",
        "\n",
        "    print(file_names[i])\n",
        "    mammo = io.imread(image_path+file_names[i],0)\n",
        "   \n",
        "    lesion_mask = io.imread(annotation_path+file_names[i])\n",
        "    \n",
        "    if np.max(lesion_mask)>=0:\n",
        "#    Extract the breast profile and crop the mammogram, breast mask and the lesion mask\n",
        "#    Normalize the image into 16-bit\n",
        "        breast_preprocess = Preprocess.extract_breast_profile(mammo,lesion_mask,1)\n",
        "               \n",
        "        mammo = breast_preprocess.image\n",
        "        breast_mask = breast_preprocess.mask\n",
        "        lesion_mask =breast_preprocess.lesion_mask    \n",
        "        \n",
        "        print ('Number of lesions: '+str(np.max(np.unique(label(lesion_mask)))))\n",
        "        \n",
        "#   pad the image, to ensure the aspect ratio is 1:1\n",
        "        pad_mammo = padimages(mammo,file_names[i],1)\n",
        "        \n",
        "#    save the preprocessed image\n",
        "\n",
        "        io.imsave(save_image_path + file_names[i],pad_mammo)\n",
        "        \n",
        "        #if the image has more than 1 lesion, then seperate them into different masks and number them.\n",
        "        \n",
        "        labelim = label(lesion_mask)\n",
        "        if np.max(labelim)>0:\n",
        "#            if there is at least 1 lesion.\n",
        "            for l in range(1,np.max(labelim+1)):\n",
        "                l_mask = np.zeros(np.shape(labelim))\n",
        "                l_mask = l_mask.astype(lesion_mask.dtype)\n",
        "                l_mask [labelim==l] = 255\n",
        "                num_nonzero = np.where(l_mask>0)\n",
        "                num_nonzero = len(num_nonzero[0])\n",
        "\n",
        "                if num_nonzero>15:\n",
        "                    print('A valid mask')\n",
        "#                   Pad the mask in the same way as padding the image\n",
        "                    pad_l_mask = padimages(l_mask,file_names[i],1)\n",
        "                    io.imsave(save_mask_path+file_names[i][:-4]+str(l)+'.png',pad_l_mask)\n",
        "                else:\n",
        "                    print('Has a tiny piece of noise that is not valid for training!')\n",
        "                    \n",
        "        else:# if there is no lesion\n",
        "            pad_lesion_mask = padimages(lesion_mask,file_names[i],1)\n",
        "            io.imsave(save_mask_path+file_names[i][:-4]+str(0)+'.png',pad_lesion_mask)\n",
        "       \n",
        "stop = timeit.default_timer()\n",
        "print('RunTime per image: ', (stop - start)/ len(file_names)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22580192_5530d5782fc89dd7_MG_R_CC_ANON.png\n",
            "Number of lesions: 1\n",
            "This image needs padding.\n",
            "A valid mask\n",
            "This image needs padding.\n",
            "RunTime per image:  3.0428667979999773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPZDLxxlyh7A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuxaaw7tyh-G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1Nlg_mvyiBp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cybVGyONyiL2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASLMBKkbyikn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH2fqDNbJ-Pr"
      },
      "source": [
        "!pip install keras==2.1.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDfJW1E5KBZf"
      },
      "source": [
        "!pip install tensorflow==1.14.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9aaWLja7f4V"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3YweWp2KBc9",
        "outputId": "d4501eb9-4bd6-4956-9460-181ac4f69b9b"
      },
      "source": [
        "cd '/content/drive/MyDrive/Mammographic'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Mammographic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8nCVl1lLW42",
        "outputId": "aabe3e70-dcd4-4244-fd99-5653a4c4af2a"
      },
      "source": [
        "!git clone https://github.com/DavidReveloLuna/MaskRCNN_Video.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'MaskRCNN_Video' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFdFP5Q7KBfp"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import datetime\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "import matplotlib.image\n",
        "import glob\n",
        "import scipy.misc\n",
        "from PIL import Image\n",
        "#import imgaug \n",
        "from imgaug import augmenters as iaa\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XemznmFPKMsK"
      },
      "source": [
        "# Root directory of the project\n",
        "ROOT_DIR = os.getcwd()\n",
        "ROOT_DIR = ROOT_DIR+\"/Mask_r_cnn\"\n",
        "\n",
        "MAMOGRAM_IMAGE_DIR = \"/scans/pseudo_color_image/\" #Path of the mammograms\n",
        "MAMOGRAM_MASK_DIR = \"/scans/preprocessed_mask/\"# Path of the ground truth masks\n",
        "\n",
        "\n",
        "# Import Mask RCNN\n",
        "sys.path.append(ROOT_DIR) # To find local version of the library\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import model as modellib, utils\n",
        "\n",
        "# Path to trained weights file\n",
        "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_balloon.h5\")\n",
        "\n",
        "# Directory to save logs and model checkpoints, if not provided\n",
        "# through the command line argument --logs\n",
        "DEFAULT_LOGS_DIR = os.path.join(\"/content/drive/MyDrive/Mammographic\", \"logs\")#Log directory for saving the weights\n",
        "DEMO_SAVE_DIR = \"/scans/seg_mask/\"# path to save the segmentation masks\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwHFrfmIKSV6"
      },
      "source": [
        "############################################################\n",
        "#  Configurations\n",
        "############################################################\n",
        "\n",
        "\n",
        "class MamogramConfig(Config):\n",
        "    \"\"\"Configuration for training on the toy  dataset.\n",
        "    Derives from the base Config class and overrides some values.\n",
        "    \"\"\"\n",
        "    # Give the configuration a recognizable name\n",
        "    NAME = \"mamogram\"\n",
        "\n",
        "    # We use a GPU with 12GB memory, which can fit two images.\n",
        "    # Adjust down if you use a smaller GPU.\n",
        "    IMAGES_PER_GPU = 1\n",
        "\n",
        "    # Number of classes (including background)\n",
        "    NUM_CLASSES = 1 + 1  # Background + lesion\n",
        "\n",
        "    # Number of training steps per epoch,set to the number of training data here\n",
        "    STEPS_PER_EPOCH = 5\n",
        "\n",
        "    # Number of validation steps after each round of training\n",
        "    VALIDATION_STEPS = 2\n",
        "    # Resize mode: \"none\" or \"square\"\n",
        "\n",
        "    IMAGE_RESIZE_MODE = \"square\"\n",
        "    IMAGE_MIN_DIM = 1024\n",
        "    IMAGE_MAX_DIM = 1024\n",
        "\n",
        "    # Skip detections with < DETECTION_MIN_CONFIDENCE\n",
        "    DETECTION_MIN_CONFIDENCE = 0.965 # alter this during testing to generate different TPR at different FPI\n",
        "    # 0.7 0.75 0.8 0.85 0.9"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVXJ7BV7KSZC"
      },
      "source": [
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class MamogramDataset(utils.Dataset):\n",
        "\n",
        "    def load_mamogram(self, subset):\n",
        "        \"\"\"This method loads the actual image\n",
        "        subset is either \"train\" or \"val\" depending on whether the image is part of the training or validation datasets \n",
        "        \"\"\"\n",
        "        # Add classes. We have only one class to add.\n",
        "        # These are the things that will be segmented\n",
        "        self.add_class(\"mamogram\", 1, \"lesion\")\n",
        "\n",
        "        # Train or validation dataset?\n",
        "\n",
        "        #list all the files in the directory with the mamogram images\n",
        "        files = os.listdir(ROOT_DIR + MAMOGRAM_IMAGE_DIR + subset + \"/\")\n",
        "        \n",
        "        for fname in files:            \n",
        "            self.add_image(\"mamogram\", image_id=fname, \n",
        "                           path=ROOT_DIR + MAMOGRAM_IMAGE_DIR + subset +\"/\"+ fname, subset=subset, fname=fname)\n",
        "\n",
        "\n",
        "    def load_mask(self, image_id):\n",
        "        \"\"\"load the instance masks for an image.\n",
        "        Returns:\n",
        "        a tuple containing:\n",
        "        masks: A bool array of shape [height, width, instance count] with\n",
        "        one mask per instance.\n",
        "        class_ids: a 1D array of class IDs of the instance masks.\n",
        "        use dtype=np.int32\n",
        "        \"\"\"\n",
        "        image_info = self.image_info[image_id]\n",
        "        info = self.image_info[image_id]\n",
        "        fname = info['fname']\n",
        "        #count=len(fname)\n",
        "       \n",
        "\n",
        "        #files = glob.glob(ROOT_DIR + MAMOGRAM_MASK_DIR + info['subset']+\"/\" + fname[0:-4] + \"*\")\n",
        "        #files=ROOT_DIR + MAMOGRAM_MASK_DIR + \"train\" +\"/\"+ fname\n",
        "        files = glob.glob(ROOT_DIR + MAMOGRAM_MASK_DIR + info['subset']+\"/\" + fname[0:-4] + \"*\")\n",
        "        #print(files)\n",
        "        \n",
        "\n",
        "        masks = []\n",
        "        for i in range(0, len(files)):\n",
        "            #print(i)\n",
        "            data = skimage.io.imread(files[i])\n",
        "            \n",
        "            if data.ndim != 1:\n",
        "                data = skimage.color.rgb2gray(data)\n",
        "          \n",
        "            singleMask = data\n",
        "            if i == 0:\n",
        "                masks = np.zeros((singleMask.shape[0], singleMask.shape[1], len(files)))\n",
        "            masks[:,:,i] = singleMask\n",
        "            #masks=np.array(masks)\n",
        "\n",
        "        instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
        "        #instanceMaskMap = [masks.shape[-1]]\n",
        "        \n",
        "        return (masks.astype(np.bool), instanceMaskMap)\n",
        "\n",
        "\n",
        "        #class_ids = np.array([self.class_names.index(s[0]) for s in fname])\n",
        "        #return mask.astype(np.bool), class_ids.astype(np.int32)\n",
        "         #this is VERY important: array of class ids in the order that they appear in bigdata\n",
        "        # Return mask, and array of class IDs of each instance. Since we have\n",
        "        # one class ID only, we return an array of 1\n",
        "\n",
        "    def load_image(self, image_id):\n",
        "        \"\"\"Load the specified image and return a [H,W,3] Numpy array.\n",
        "\t\tTaken from utils.py, any refinements we need can be done here\n",
        "        \"\"\"\n",
        "        # Load image\n",
        "        image = skimage.io.imread(self.image_info[image_id]['path'])\n",
        "        # If grayscale. Convert to RGB for consistency.\n",
        "        if image.ndim != 3:\n",
        "            image = skimage.color.gray2rgb(image)\n",
        "        # If has an alpha channel, remove it for consistency\n",
        "        if image.shape[-1] == 4:\n",
        "            image = image[..., :3]\n",
        "        return image\n",
        "\n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        return info[\"path\"]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6LHNTgOKSb4"
      },
      "source": [
        "def train(model):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = MamogramDataset()\n",
        "    dataset_train.load_mamogram(\"train\")\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    #dataset_val = MamogramDataset()\n",
        "    #dataset_val.load_mamogram(\"val\")\n",
        "    #dataset_val.prepare()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Image augmentation\n",
        "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
        "    aug = iaa.Sequential([\n",
        "        iaa.OneOf([iaa.Fliplr(0.5),\n",
        "                   iaa.Flipud(0.5),\n",
        "                   iaa.Affine(rotate=90),\n",
        "                   iaa.Affine(rotate=180),\n",
        "                   iaa.Affine(rotate=270)]),\n",
        "    ])\n",
        "\n",
        "    # *** This training schedule is an example. Update to your needs ***\n",
        "    # Since we're using a very small dataset, and starting from\n",
        "    # COCO trained weights, we don't need to train too long. Also,\n",
        "    # no need to train all layers, just the heads should do it.\n",
        "    print(\"Training network heads\")\n",
        "\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=config.LEARNING_RATE,\n",
        "                epochs=3,augmentation=aug,\n",
        "                layers='heads')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FETRtQIn3iyB"
      },
      "source": [
        " # Training dataset.\n",
        "dataset_train = MamogramDataset()\n",
        "dataset_train.load_mamogram(\"train\")\n",
        "dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "dataset_val = MamogramDataset()\n",
        "dataset_val.load_mamogram(\"val\")\n",
        "dataset_val.prepare()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzJnXQhA21uV",
        "outputId": "baf96146-e0bf-407c-c6d3-72a530ce3323"
      },
      "source": [
        "print(dataset_val.class_names)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['BG', 'lesion']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPkgRjNm6LMs"
      },
      "source": [
        "config = MamogramConfig()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKbFhvqR5y6L"
      },
      "source": [
        "model = modellib.MaskRCNN(mode=\"training\", config=config,model_dir=DEFAULT_LOGS_DIR)\n",
        "model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n",
        "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
        "            \"mrcnn_bbox\", \"mrcnn_mask\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDbTWwQv2mcA"
      },
      "source": [
        "dataset = dataset_train\n",
        "image_ids = np.random.choice(dataset.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset.load_image(image_id)\n",
        "    masks, num_ids = dataset.load_mask(image_id)\n",
        "    print(image,masks,num_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3hbUTCFasou",
        "outputId": "83aaa1c6-3315-4df7-bad9-b183a97030ac"
      },
      "source": [
        "config = MamogramConfig()\n",
        "#config.display()\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "weights_path = COCO_WEIGHTS_PATH\n",
        "\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "train(model)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/drive/MyDrive/Mammographic/logs/mamogram20210327T1841/mask_rcnn_mamogram_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "4/5 [=======================>......] - ETA: 1:14 - loss: 155.5872 - rpn_class_loss: 23.3238 - rpn_bbox_loss: 132.2633 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 432s 86s/step - loss: 154.4079 - rpn_class_loss: 22.1797 - rpn_bbox_loss: 132.2281 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 276.1230 - val_rpn_class_loss: 15.1062 - val_rpn_bbox_loss: 261.0169 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
            "Epoch 2/3\n",
            "5/5 [==============================] - 342s 68s/step - loss: 210.9497 - rpn_class_loss: 8.5504 - rpn_bbox_loss: 202.3993 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 262.2912 - val_rpn_class_loss: 1.1692 - val_rpn_bbox_loss: 261.1220 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n",
            "Epoch 3/3\n",
            "5/5 [==============================] - 340s 68s/step - loss: 247.8848 - rpn_class_loss: 0.4075 - rpn_bbox_loss: 247.4774 - mrcnn_class_loss: 2.3842e-08 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00 - val_loss: 269.0687 - val_rpn_class_loss: 0.0232 - val_rpn_bbox_loss: 269.0455 - val_mrcnn_class_loss: 0.0000e+00 - val_mrcnn_bbox_loss: 0.0000e+00 - val_mrcnn_mask_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lVeFsfkSV--Q",
        "outputId": "09dd7251-c2a4-4c23-b46b-dd8005259d49"
      },
      "source": [
        "config = MamogramConfig()\n",
        "#config.display()\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "weights_path = COCO_WEIGHTS_PATH\n",
        "\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "train(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training network heads\n",
            "\n",
            "Starting at epoch 0. LR=0.001\n",
            "\n",
            "Checkpoint Path: /content/drive/MyDrive/Mammographic/logs/mamogram20210327T1553/mask_rcnn_mamogram_{epoch:04d}.h5\n",
            "Selecting layers to train\n",
            "fpn_c5p5               (Conv2D)\n",
            "fpn_c4p4               (Conv2D)\n",
            "fpn_c3p3               (Conv2D)\n",
            "fpn_c2p2               (Conv2D)\n",
            "fpn_p5                 (Conv2D)\n",
            "fpn_p2                 (Conv2D)\n",
            "fpn_p3                 (Conv2D)\n",
            "fpn_p4                 (Conv2D)\n",
            "In model:  rpn_model\n",
            "    rpn_conv_shared        (Conv2D)\n",
            "    rpn_class_raw          (Conv2D)\n",
            "    rpn_bbox_pred          (Conv2D)\n",
            "mrcnn_mask_conv1       (TimeDistributed)\n",
            "mrcnn_mask_bn1         (TimeDistributed)\n",
            "mrcnn_mask_conv2       (TimeDistributed)\n",
            "mrcnn_mask_bn2         (TimeDistributed)\n",
            "mrcnn_class_conv1      (TimeDistributed)\n",
            "mrcnn_class_bn1        (TimeDistributed)\n",
            "mrcnn_mask_conv3       (TimeDistributed)\n",
            "mrcnn_mask_bn3         (TimeDistributed)\n",
            "mrcnn_class_conv2      (TimeDistributed)\n",
            "mrcnn_class_bn2        (TimeDistributed)\n",
            "mrcnn_mask_conv4       (TimeDistributed)\n",
            "mrcnn_mask_bn4         (TimeDistributed)\n",
            "mrcnn_bbox_fc          (TimeDistributed)\n",
            "mrcnn_mask_deconv      (TimeDistributed)\n",
            "mrcnn_class_logits     (TimeDistributed)\n",
            "mrcnn_mask             (TimeDistributed)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "4/5 [=======================>......] - ETA: 1:10 - loss: 159.0087 - rpn_class_loss: 22.9659 - rpn_bbox_loss: 136.0428 - mrcnn_class_loss: 0.0000e+00 - mrcnn_bbox_loss: 0.0000e+00 - mrcnn_mask_loss: 0.0000e+00"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
            "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
            "ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/val/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': 'val', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/val/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': 'val', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/val/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': 'val', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/val/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': 'val', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/val/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': 'val', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/val/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': 'val', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/val/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': 'val', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/val/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': 'val', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 677, in _data_generator_task\n",
            "    generator_output = next(self._generator)\n",
            "ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/val/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': 'val', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n",
            "ERROR:root:Error processing image {'id': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'source': 'mamogram', 'path': '/content/drive/MyDrive/Mammographic/Mask_r_cnn/scans/pseudo_color_image/val/22580192_5530d5782fc89dd7_MG_R_CC_ANON.png', 'subset': 'val', 'fname': '22580192_5530d5782fc89dd7_MG_R_CC_ANON.png'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1709, in data_generator\n",
            "    use_mini_mask=config.USE_MINI_MASK)\n",
            "  File \"/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\", line 1212, in load_image_gt\n",
            "    mask, class_ids = dataset.load_mask(image_id)\n",
            "  File \"<ipython-input-10-09649e7b9567>\", line 60, in load_mask\n",
            "    instanceMaskMap = np.array(np.ones([masks.shape[-1]], dtype=np.int32))\n",
            "AttributeError: 'list' object has no attribute 'shape'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-21978f6d91a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-fc408e734c51>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maugmentation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maug\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 layers='heads')\n\u001b[0m",
            "\u001b[0;32m/content/drive/MyDrive/Mammographic/Mask_r_cnn/mrcnn/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, learning_rate, epochs, layers, augmentation, custom_callbacks, no_augmentation_sources)\u001b[0m\n\u001b[1;32m   2372\u001b[0m             \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2374\u001b[0;31m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2375\u001b[0m         )\n\u001b[1;32m   2376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2242\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2243\u001b[0m                                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2244\u001b[0;31m                                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[1;32m   2245\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m                     raise ValueError('Output of generator should be a tuple '\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJZgpowKKSet"
      },
      "source": [
        "def segment(model, imPath):\n",
        "    \n",
        "    image = skimage.io.imread(imPath)\n",
        "\n",
        "    fname = imPath.split('/')[-1]\n",
        "    mrcnnData = model.detect([image], verbose=1)\n",
        "       # documentation for model.detect:\n",
        "       # \"\"\"Runs the detection pipeline.\n",
        "\n",
        "       # images: List of images, potentially of different sizes.\n",
        "\n",
        "       # Returns a list of dicts, one dict per image. The dict contains:\n",
        "       # rois: [N, (y1, x1, y2, x2)] detection bounding boxes\n",
        "       # class_ids: [N] int class IDs\n",
        "       # scores: [N] float probability scores for the class IDs\n",
        "       # masks: [H, W, N] instance binary masks\n",
        "       # \"\"\"\n",
        "\n",
        "    mrcnnData = mrcnnData[0] #model.detect takes a list of images, but here we only provide one image so the output is a list with just one element\n",
        "\n",
        "    masks = mrcnnData['masks']\n",
        "    for i in range(0, masks.shape[2]):\n",
        "        #iterate through the masks\n",
        "        maskSingle = np.squeeze(masks[:, :, i])\n",
        "        file_name = DEMO_SAVE_DIR + \"demo_mask_\" + str(i) + \"_\" + fname + \"_{:%Y%m%dT%H%M%S}.png\".format(datetime.datetime.now())\n",
        "        \n",
        "\n",
        "        scipy.misc.imsave(file_name, maskSingle.astype(np.int64)) \n",
        "\n",
        "\n",
        "    print(mrcnnData)\n",
        "    print(\"&&&&&&&&&&&: \"+str(mrcnnData['rois']))\n",
        "    print(\"&&&&&&&&&&&: \"+str(mrcnnData['class_ids']))\n",
        "    print(\"&&&&&&&&&&&: \"+str(mrcnnData['scores']))\n",
        "\n",
        "    return\n",
        "\n",
        "def segmentWrapper(model, directory):\n",
        "    \"\"\"wrapper function for segment to take many images as an input, \n",
        "    calls segment() on everything in the directory\"\"\"\n",
        "    files = os.listdir(directory)\n",
        "    for f in files:\n",
        "        segment(model, directory + '/' + f)\n",
        "\n",
        "\n",
        "\n",
        "def overlayResult(image, mask):\n",
        "\t\"\"\"Function to overlay segmentation mask on an image.\n",
        "\tusage: image_var = overlayResult(image, dict['masks'] || masks_var)\n",
        "\t\n",
        "\timage: RGB or grayscale image [height, width, 1 || 3].\n",
        "\tmask: segmentation mask [height, width, instance_count]\n",
        "\t\n",
        "\treturns resulting image.\n",
        "\t\"\"\"\n",
        "\t# Image is already in grayscale so we skip converting it\n",
        "\t# May need to create 3 dimensions if single dimension image though so\n",
        "\t# will add this as a placeholder\n",
        "\tgray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255\n",
        "\t# Copy color pixels from the original color image where mask is set\n",
        "\tif mask.shape[-1] > 0:\n",
        "\t\t#collapse masks into one layer\n",
        "\t\tmask = (np.sum(mask, -1, keepdims=True) >= 1)\n",
        "\t\toverlay = np.where(mask, image, gray).astype(np.uint8)\n",
        "\telse:\n",
        "\t\toverlay = gray.astype(np.uint8)\n",
        "\t\t\n",
        "\treturn overlay\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gFDogcuVn7h"
      },
      "source": [
        "config = MamogramConfig()\n",
        "#config.display()\n",
        "\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "weights_path = COCO_WEIGHTS_PATH\n",
        "\n",
        "\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "train(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDD33c_03cgE"
      },
      "source": [
        "class InferenceConfig(MamogramConfig):\n",
        "            # Set batch size to 1 since we'll be running inference on\n",
        "            # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
        "            GPU_COUNT = 1\n",
        "            IMAGES_PER_GPU = 1\n",
        "        config = InferenceConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dzXqDNX2BCl"
      },
      "source": [
        "config = MamogramConfig()\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
        "                                  model_dir=DEFAULT_LOGS_DIR)\n",
        "weights_path = COCO_WEIGHTS_PATH\n",
        "model.load_weights(weights_path, by_name=True)\n",
        "segmentWrapper(model, args.image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smp6f-ACUgGO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoD73JXJUgJe"
      },
      "source": [
        "!python mamo_CAD.py train --weights=mask_rcnn_balloon.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbAxNISvUg_w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}